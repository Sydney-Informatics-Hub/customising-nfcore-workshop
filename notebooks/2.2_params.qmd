---
title: "**Using a parameter file**"
output:
  html_document:
    toc: false
    toc_float: false
from: markdown+emoji
---

::: callout-tip
### Objectives{.unlisted}

- Write a parameter file
- Understand the YAML file format 
- Rerun the workflow using a params file 
- Understand the use of the params file for reproducible and transparent research
:::

In Nextflow, parameters are values that can be set by the user and used to control the behaviour of a workflow or process within the workflow. Parameters are also used in nf-core workflows to specify input and output files and define other aspects of workflow execution. Each nf-core pipeline comes with a default set of parameters that can be customised to suit specific requirements. In the previous lesson we supplied these parameters in our run command, on the command line. 

Nextflow allows us to pass all parameters to a pipeline's run command using the `-params-file` flag and a JSON or YAML file. Using a parameter file makes it easier to rerun and reproduce our code, we can also share these files with our collaborators and provide as supplementary file in a publication. In this lesson we're going to adjust our run command and rerun the pipeline using a parameter file, rather than specifying all parameters on the command line.  

### **Revise the run command**

While our pipeline completed successfully, there were a couple of warning messages that may be cause for concern:

```default
-[nf-core/rnaseq] Pipeline completed successfully with skipped sampl(es)-
-[nf-core/rnaseq] Please check MultiQC report: 6/6 samples failed strandedness check.-
Completed at: 21-Apr-2023 03:58:56
Duration    : 13m 59s
CPU hours   : 0.4
Succeeded   : 200
```

The first warning message isn't very descriptive- do we have a problem or not? As we were developing these materials we flagged this with the nf-core/rnaseq pipeline's developers (see [pull request](https://github.com/nf-core/rnaseq/pull/963)). You might come across small but inconsequential issues like this when running nf-core pipelines, too. Consider submitting a GitHub issue or flagging this in the pipeline's Slack channel so others are aware and it can be addressed by developers. Turns out this wasn't a problem for our pipeline, so instead let's focus on the second message.

Let's take a look at the MultiQC report, as directed by the message. You can find this report in the `Lesson-1/` directory: 

```default
ls -la Lesson1/multiqc/star_salmon/
```

```default
total 1468
drwxrwxr-x 4 ubuntu ubuntu    4096 Apr 12 04:13 .
drwxrwxr-x 3 ubuntu ubuntu    4096 Apr 12 04:13 ..
drwxrwxr-x 2 ubuntu ubuntu    4096 Apr 12 04:13 multiqc_data
drwxrwxr-x 5 ubuntu ubuntu    4096 Apr 12 04:13 multiqc_plots
-rw-rw-r-- 1 ubuntu ubuntu 1483297 Apr 12 04:13 multiqc_report.html
```

Open the `multiqc_report.html` the file navigator panel on the left side of your VS code window by clicking on it. Then open the rendered html file using the Live Server extension:

1. `Ctrl`+`Shift`+`P` to open the command palette 
2. Select `Live Server: Open with Live Server` to open html file in your browser window.

Take a look a the section labelled **WARNING: Fail Strand Check**

![](https://user-images.githubusercontent.com/73086054/231065216-940fb01f-a7dc-416c-a481-27676bbcfff3.png)

The issue here is **provided strandedness** that we specified in our `samplesheet.csv` and **inferred strandedness** identified by Salmon do not match. Look's like we've incorrectly specified strandedness as forward in the `samplesheet.csv` (my mistake! :expressionless:) when our raw reads actually show an equal distribution of sense and antisense reads. Let's check how the nf-core/rnaseq pipeline ran the Salmon quantification process so we can explore whether or not this will potentially have an impact on our results. 

### **Identify the run command for a process**

To understand what command is being run for a process, you can attempt to infer this information from a process `main.nf` script in the `modules/` directory. However, given all the different parameters that may be applied, this may not be straight forward. To understand what Salmon is doing, we're going to use the `nextflow log` command and some custom bash code to track down the hidden `.command.sh` scripts for each Salmon quant process to find out how Salmon quant identified library type.  

Use the [Nextflow log](https://www.nextflow.io/docs/latest/tracing.html#execution-log) command to reveal information about executed pipelines in our working directory: 

```default
nextflow log
```
This will print a list of executed pipelines, by default: 

```default
TIMESTAMP               DURATION        RUN NAME                STATUS  REVISION ID     SESSION ID                        COMMAND                                                                                                                                                                                                                                                                                                                                                                                                            
2023-04-21 03:42:56     -               scruffy_gilbert         -       f421ddc35d      a1cada83-a732-4a8b-9535-aafce197367d nextflow run nf-core-rnaseq-3.11.1/workflow/main.nf --input samplesheet.csv -profile singularity --fasta /home/ubuntu/session2/materials/mm10_reference/mm10_chr18.fa --gtf /home/ubuntu/session2/materials/mm10_reference/mm10_chr18.gtf --star_index /home/ubuntu/session2/materials/mm10_reference/STAR --max_memory '7 GB' --max_cpus 2 --outdir Lesson-1
```

All recent runs will be listed in this file, with the most recent at the top. Let's query the logs for the Lesson-1 run. Run the command below after filling in your unique run name. For example: 

```default
nextflow log scruffy_gilbert
```

That command will list out all the work sub-directories for all processes run.  Recall that the actual tool commands issued by the nexflow processes are all recorded in hidden script files called `.command.sh` within the execution process directory. One way of observing the actual run commands issued by the workflow is to view these comamnd scripts. But how to find them?! Let's add some custom bash code to query a Nextflow run with the run name from the previous lesson.  

First, save your run name in a bash variable. For example:
```default
run_name=scruffy_gilbert
```

And let's save the tool of interest (salmon) in another bash variable:
```default
tool=salmon
```

Next, run the following bash command:
```default
nextflow log ${run_name} | while read line;
    do
    cmd=$(ls ${line}/.command.sh 2>/dev/null);
      if grep -q $tool $cmd;
      then  
        echo $cmd;     
      fi; 
    done 
```

That will list all process `.command.sh` scripts containing 'salmon'. There are multiple salmon steps in the workflow, inlcuding index and an R script. We are looking for salmon quant which performs the read quantification. For example: 

```default
/home/ubuntu/session2/work/50/d4462ece237213ace901a779a45286/.command.sh
/home/ubuntu/session2/work/2f/11774c859f9f55f816b754a65290a7/.command.sh
/home/ubuntu/session2/work/bc/0478d8de4d1c6df1413c50f4bffcb1/.command.sh
/home/ubuntu/session2/work/af/57d1741b614927225fe6381333d615/.command.sh
/home/ubuntu/session2/work/e6/6a644b0d85f03ec91cd2efe5a485d2/.command.sh
/home/ubuntu/session2/work/7d/ff697b987403d2f085b8b538260b67/.command.sh
/home/ubuntu/session2/work/3e/1b7b0f03c7c7c462a4593f77be544e/.command.sh
/home/ubuntu/session2/work/31/5e6865dbbbb164a87d2254b68670fa/.command.sh
/home/ubuntu/session2/work/79/93034bd48f5a0de82e79a1fd12f6ac/.command.sh
/home/ubuntu/session2/work/ca/bbfba0ea604d479bdc4870e9b3b4ce/.command.sh
/home/ubuntu/session2/work/ec/0a013bfb1f96d3c7170137262294e7/.command.sh
/home/ubuntu/session2/work/b7/37428bc5be1fd2c34e3911fb827334/.command.sh
/home/ubuntu/session2/work/57/a18fcea6a06565b14140ab06a3d077/.command.sh
```

Compare the salmon quant command with the command run in the Salmon quant process script block:
```default
cat rnaseq/modules/nf-core/salmon/quant/main.nf
```

Compared with the salmon quant `main.nf` file, we get more information from the `.command.sh` process scripts: 

![](../figs/2.2_salmon-quant.png)

Looking at the nf-core/rnaseq documentation, we can see library type is automatically inferred based on provided strandedness and this can be overridden using Salmon's `--libType=$strandedness` flag. Following the recommendations in the [Salmon documentation](https://salmon.readthedocs.io/en/latest/salmon.html#what-s-this-libtype), we're going to override this default with the nf-core/rnaseq pipeline's `--salmon_quant_libtype A` [parameter](https://nf-co.re/rnaseq/3.11.1/parameters#salmon_quant_libtype). 

### **Write a parameter file**

Nextflow accepts either YAML or JSON formats for parameter files. YAML and JSON are formats for storing data objects and structures in a file and either is a valid choice for building your parameters file. We will create and apply a YAML file with our inputs for our second run, just because its easier to read. YAML files follow these syntax rules: 

* YAML is case sensitive 
* The files should have a yaml or yml as the file extension 
* YAML does not allow the use of tabs, only spaces
* Uses 3 dashes (-\-\-) to indicate the start of a document and 3 dots (...) to indicate the end
* Uses an indentation heirarchy like Python to show a heirarchy in the data 
* Key/value pairs are separated by a colon (:) (i.e. input: "samplesheet.csv")
* Lists begin with a hyphen 
* Each key and value must be unique
* The order of keys or values in a list doesn't matter

::: callout-tip
### **Challenge**{.unlisted}

Using the syntax rules above: 

1. Write a YAML file for the parameters run command that can be run by a collaborator working on a **different computational infrastructure** but the **same input and reference files**.
2. Add a key for the `--salmon_quant_libtype A` flag, we have added to the pipeline.

```default
nextflow run nf-core-rnaseq-3.11.1/workflow/main.nf \
    --input samplesheet.csv \
    -profile singularity \
    --fasta $materials/mm10_reference/mm10_chr18.fa \
    --gtf $materials/mm10_reference/mm10_chr18.gtf \
    --star_index $materials/mm10_reference/STAR \
    --max_memory '6 GB' \
    --max_cpus 2 
    --outdir Lesson-2
```

:bulb: HINT: you will only need to specify nf-core/rnaseq parameters (i.e. `--` flags)
:::

::: {.callout-caution collapse="true"}
### Solution

Save this file as `params.yaml`:

```yaml
# experiment: WT vs KO mouse model
# workflow: nf-core/rnaseq/3.11.1 
---
input: "samplesheet.csv" 
outdir: "Lesson-2"
gtf: "/home/ubuntu/session2/materials/mm10_reference/mm10_chr18.gtf"
fasta: "/home/ubuntu/session2/materials/mm10_reference/mm10_chr18.fa"
star_index: "/home/ubuntu/session2/materials/mm10_reference/STAR" 
salmon_quant_libtype : A
...
```
:::

Any of the pipeline [parameters](https://nf-co.re/rnaseq/3.11.1/parameters) can be added to the parameters file in this way.

### **Pass the parameter file to the run command**

Once your params file has been saved, run the following command. Observe:

* The command is shorter thanks to offloading some parameters to the params file
* The `-resume` flag. Nextflow can use cached output!

```default
nextflow run nf-core-rnaseq-3.11.1/workflow/main.nf \
  --max_memory 6.GB \
  --max_cpus 2 \
  -profile singularity \
  -resume \
  -params-file params.yaml \
  --outdir Lesson-2                                 
```

As we've used the `-resume` flag, the initial pre-processing stage and STAR alignments should to be restored from cache and only the Salmon and downstream QC steps will be recomputed. The rerun workflow should complete in a much shorter time.

```default
-[nf-core/rnaseq] Pipeline completed successfully with skipped sampl(es)-
-[nf-core/rnaseq] Please check MultiQC report: 6/6 samples failed strandedness check.-
Completed at: 21-Apr-2023 05:58:06
Duration    : 2m 1s
CPU hours   : 0.4 (85.9% cached)
Succeeded   : 15
Cached      : 185
```

::: {.callout-note}
### **Key points**
- A parameter file can be used to specify input parameters for any Nextflow workflow.
- Specify parameter files in a workflow run command using the `-params-file` flag. 
- Parameter files can be written in YAML or JSON file formats.  
:::

