---
title: "**2.2. How to use a parameters file**"
output:
  html_document:
    toc: false
    toc_float: false
from: markdown+emoji
---

::: callout-tip
### Objectives{.unlisted}

- Investigate a warning message provided by an nf-core pipeline run
- Use the `nextflow log` command to trace processes cached in the work directory
- Observe how a process is implemented at the task level
- Rerun a workflow using a parameter file to specify pipeline-specific parameters
- Understand the use of the parameter file for reproducible and transparent research
:::

In Nextflow, [parameters](https://www.nextflow.io/docs/latest/config.html#scope-params) are values that can be set by the user and used to control the behaviour of a workflow or process within the workflow. Within the Nextflow code base, they are defined by the `params{}` scope. 

In the previous lesson we supplied parameters as flags in our run command. Alternatively, we can pass pipeline-specific parameters to any pipeline using Nextflow's `-params-file` flag and a JSON or YAML file. This feature has been implemented by nf-core developers and it can enable reproducibility and collaboration. In this lesson we will adjust our run command and rerun the pipeline using a parameter file, rather than specifying all parameters as separate flags in the run command.  

### **2.2.1. Revise the run command**

While our pipeline completed successfully, there were a couple of warning messages that may be cause for concern:

```default
-[nf-core/rnaseq] Pipeline completed successfully with skipped sampl(es)-
-[nf-core/rnaseq] Please check MultiQC report: 6/6 samples failed strandedness check.-
Completed at: 21-Apr-2023 03:58:56
Duration    : 14m 18s
CPU hours   : 0.4
Succeeded   : 170
```

::: {.callout-warning}
### Handling dodgy error messages :cursing_face:
The first warning message isn't very descriptive (see this [pull request](https://github.com/nf-core/rnaseq/pull/963)). You might come across issues like this when running nf-core pipelines, too. Bug reports and user feedback is very important to open source software communities like nf-core. If you come across any issues submit a GitHub issue or start a discussion in the relevant nf-core Slack channel so others are aware and it can be addressed by the pipeline's developers.
:::

Take a look at the MultiQC report, as directed by the second message. You can find the MultiQC report in the `Lesson-2.1/` directory: 

```default
ls -la Lesson-2.1/multiqc/star_salmon/
```

```default
total 1468
drwxrwxr-x 4 ubuntu ubuntu    4096 Apr 12 04:13 .
drwxrwxr-x 3 ubuntu ubuntu    4096 Apr 12 04:13 ..
drwxrwxr-x 2 ubuntu ubuntu    4096 Apr 12 04:13 multiqc_data
drwxrwxr-x 5 ubuntu ubuntu    4096 Apr 12 04:13 multiqc_plots
-rw-rw-r-- 1 ubuntu ubuntu 1483297 Apr 12 04:13 multiqc_report.html
```

Open the `multiqc_report.html` the file navigator panel on the left side of your VS Code window by clicking on it. Then open the rendered html file using the Live Server extension:

1. `Ctrl`+`Shift`+`P` to open the command palette 
2. Select `Live Server: Open with Live Server` to open html file in your browser window.

Take a look a the section labelled **WARNING: Fail Strand Check**

![](https://user-images.githubusercontent.com/73086054/231065216-940fb01f-a7dc-416c-a481-27676bbcfff3.png)

The warning we have received is indicating that the read strandedness we specified in our `samplesheet.csv` and **inferred strandedness** identified by the pipeline do not match. Look's like I have incorrectly specified strandedness as forward in the `samplesheet.csv` when our raw reads actually show an equal distribution of sense and antisense reads (my mistake! :expressionless:). 

For those not familiar with RNAseq data, this could have a big impact on our results at the read quantification step (Salmon quant). So, let's clarify what the Salmon quant process is doing and find a way to address this with the parameters provided by the nf-core/rnaseq pipeline.

### **2.2.2. Identify the run command for a process**

To understand what command is being run for a process, we can attempt to infer this information from a process `main.nf` script in the `modules/` directory. However, given all the different parameters that may be applied at the process level, this may not be very clear. 

To understand what Salmon is doing, we're going to use the `nextflow log` command and some custom bash code to track down the hidden `.command.sh` scripts for each Salmon quant process to find out how Salmon quant handles strandedness and if there is a way for us to override this.  

Use the [Nextflow log](https://www.nextflow.io/docs/latest/tracing.html#execution-log) command to reveal information about previously executed pipelines: 

```default
nextflow log
```
This will print a list of executed pipelines: 

```default
TIMESTAMP               DURATION        RUN NAME                STATUS  REVISION ID     SESSION ID                              COMMAND                                                                                                                                                                                                                                                                                                                                                    
2023-04-21 00:30:30     -               friendly_montalcini     -       f421ddc35d      685266bb-b99b-4945-9a54-981e8f4b1b07    nextflow run nf-core-rnaseq-3.11.1/workflow/main.nf --help                                                                                                                                                                                                                                                                                                 
2023-04-21 00:40:58     14m 18s         mighty_swanson        OK      f421ddc35d      055e7b7f-c3ea-4fd9-a915-02343099939e    nextflow run nf-core-rnaseq-3.11.1/workflow/main.nf --input samplesheet.csv -profile singularity --fasta /home/ubuntu/session2/materials/mm10_reference/mm10_chr18.fa --gtf /home/ubuntu/session2/materials/mm10_reference/mm10_chr18.gtf --star_index /home/ubuntu/session2/materials/mm10_reference/STAR --max_memory 6.GB --max_cpus 2 --outdir Lesson-1
```

All recent runs will be listed in this file, with the most recent at the bottom. Run the command below after filling in your unique run name for our previous lesson. For example: 

```default
nextflow log mighty_swanson
```

That command will list out all the work subdirectories for all processes run.  Recall from Session 1 that the actual command issued by a processes are all recorded in hidden script files called `.command.sh` within the execution process directory. One way of observing the actual run commands issued by the workflow is to view these command scripts. 

But how to find them? :thinking: 

Let's add some custom bash code to query a Nextflow run with the run name from the previous lesson. First, save your run name in a bash variable. For example:

```default
run_name=mighty_swanson
```

And let's save the tool of interest (salmon) in another bash variable to pull it from a run command:
```default
tool=salmon
```

Next, run the following bash command:
```default
nextflow log ${run_name} | while read line;
    do
      cmd=$(ls ${line}/.command.sh 2>/dev/null);
      if grep -q $tool $cmd;
      then  
        echo $cmd;     
      fi; 
    done 
```

That will list all process `.command.sh` scripts containing 'salmon'. There are a few different processes that run Salmon in the workflow. We are looking for Salmon quant which performs the read quantification. For example: 

```default
/home/ubuntu/session2/work/50/d4462ece237213ace901a779a45286/.command.sh
/home/ubuntu/session2/work/2f/11774c859f9f55f816b754a65290a7/.command.sh
/home/ubuntu/session2/work/bc/0478d8de4d1c6df1413c50f4bffcb1/.command.sh
/home/ubuntu/session2/work/af/57d1741b614927225fe6381333d615/.command.sh
/home/ubuntu/session2/work/e6/6a644b0d85f03ec91cd2efe5a485d2/.command.sh
/home/ubuntu/session2/work/7d/ff697b987403d2f085b8b538260b67/.command.sh
/home/ubuntu/session2/work/3e/1b7b0f03c7c7c462a4593f77be544e/.command.sh
/home/ubuntu/session2/work/31/5e6865dbbbb164a87d2254b68670fa/.command.sh
/home/ubuntu/session2/work/79/93034bd48f5a0de82e79a1fd12f6ac/.command.sh
/home/ubuntu/session2/work/ca/bbfba0ea604d479bdc4870e9b3b4ce/.command.sh
/home/ubuntu/session2/work/ec/0a013bfb1f96d3c7170137262294e7/.command.sh
/home/ubuntu/session2/work/b7/37428bc5be1fd2c34e3911fb827334/.command.sh
/home/ubuntu/session2/work/57/a18fcea6a06565b14140ab06a3d077/.command.sh
```

Compared with the salmon quant `main.nf` file, we get more information from the `.command.sh` process scripts: 

```default
cat rnaseq/modules/nf-core/salmon/quant/main.nf
```

![](../figs/2.2_salmon-quant.png)

Looking at the nf-core/rnaseq documentation, we can see:

* Library type is automatically inferred based on the `$strandedness` variable
* Library type can be adjusted using Salmon's `--libType=` flag and the nf-core `$strandedness` variable. 

Following the [Salmon documentation](https://salmon.readthedocs.io/en/latest/salmon.html#what-s-this-libtype), we can override this default with the nf-core/rnaseq pipeline's `--salmon_quant_libtype U` [parameter](https://nf-co.re/rnaseq/3.11.1/parameters#salmon_quant_libtype) to indicate our data is unstrands. 

If we want to get rid of the warning message `Please check MultiQC report: 6/6 samples failed strandedness check`, we'll have to change the strandedness fields in our `samplesheet.csv`. Keep in mind, this will cause the pipeline to run from the beginning.  

### **2.2.3. Write a parameter file**

Nextflow accepts either YAML or JSON formats for parameter files. Any of the pipeline-specific [parameters](https://nf-co.re/rnaseq/3.11.1/parameters) can be supplied to a pipeline run command in this way. 

::: callout-tip
### **Challenge**{.unlisted}

1. Add the appropriate fields from your previous run command to the params file below. You'll be sharing this file with a collaborator working on a **different computational infrastructure** but the **same input and reference files**.

```yaml
input: "samplesheet.csv"
outdir: "Lesson-2.2"
fasta: "/cvmfs/data.biocommons.aarnet.edu.au/training_materials/SIH_training/UnlockNfcore_0523/mm10_reference/mm10_chr18.fa"
gtf: "/cvmfs/data.biocommons.aarnet.edu.au/training_materials/SIH_training/UnlockNfcore_0523/mm10_reference/mm10_chr18.gtf"
star_index: "/cvmfs/data.biocommons.aarnet.edu.au/training_materials/SIH_training/UnlockNfcore_0523/mm10_reference/STAR"
salmon_index: "/cvmfs/data.biocommons.aarnet.edu.au/training_materials/SIH_training/UnlockNfcore_0523/mm10_reference/salmon-index"
salmon_quant_libtype: "U"
skip_markduplicates
save_trimmed: true
save_unaligned:
```

:bulb: You only need to specify pipeline-specific parameters (i.e. `--` flags)
:::

::: {.callout-caution collapse="true"}
### Solution

Save this file as `workshop-params.yaml`:

```yaml
input: "samplesheet.csv"
outdir: "Lesson-2.2"
fasta: "/cvmfs/data.biocommons.aarnet.edu.au/training_materials/SIH_training/UnlockNfcore_0523/mm10_reference/mm10_chr18.fa"
gtf: "/cvmfs/data.biocommons.aarnet.edu.au/training_materials/SIH_training/UnlockNfcore_0523/mm10_reference/mm10_chr18.gtf"
star_index: "/cvmfs/data.biocommons.aarnet.edu.au/training_materials/SIH_training/UnlockNfcore_0523/mm10_reference/STAR"
salmon_index: "/cvmfs/data.biocommons.aarnet.edu.au/training_materials/SIH_training/UnlockNfcore_0523/mm10_reference/salmon-index"
salmon_quant_libtype: "U"
skip_markduplicates
save_trimmed: true
save_unaligned: true
```
:::

### **2.2.4. Use a parameter file in a pipeline run**

Once your params file has been saved, run:

```default
nextflow run nf-core-rnaseq-3.11.1/workflow/main.nf \
  --max_memory 6.GB \
  --max_cpus 2 \
  -profile singularity \
  -params-file workshop-params.yaml \
  -resume                        
```

The number of pipeline-specific parameters we've added to our run command has been significantly reduced. The only `--` parameters we've provided to the run command relate to how the pipeline is executed on our instances. These resource limits won't be applicable to our imaginary collaborator who will run the pipeline on a different infrastructure. 

As the workflow runs a second time, you will notice 4 things:

1. The command is much tidier thanks to offloading some parameters to the params file
2. The `-resume` flag. Nextflow has lots of [run options](https://www.nextflow.io/docs/latest/cli.html?highlight=resume#run) including the ability to use cached output!
3. Some processes will be pulled from the cache. These processes remain unaffected by our addition of a new parameter.  
4. This run of the pipline will complete in a much shorter time.

```default
-[nf-core/rnaseq] Pipeline completed successfully with skipped sampl(es)-
-[nf-core/rnaseq] Please check MultiQC report: 6/6 samples failed strandedness check.-
Completed at: 21-Apr-2023 05:58:06
Duration    : 8m 8s
CPU hours   : 0.4 (57.2% cached)
Succeeded   : 147
Cached      : 53
```

::: {.callout-note}
### **Key points**
- A parameter file can be used to specify input parameters for any Nextflow workflow.
- Specify parameter files in a workflow run command using the `-params-file` flag. 
- Parameter files can be written in YAML or JSON file formats.  
:::