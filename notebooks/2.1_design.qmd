---
title: "**2.1. Design and execute an nf-core run command**"
website:
  page-navigation: true
output:
  html_document:
    toc: false
    toc_float: false
from: markdown+emoji
---

::: callout-tip
### Objectives{.unlisted}

- Understand the levels of customisation available for nf-core pipelines
- Use the nf-core documentation to select appropriate parameters for a run command 
- Write and run a nf-core rnaseq command on the command line 
- Explore pipeline deployment and outputs 
:::

Before scaling the nf-core/rnaseq pipeline up to a full dataset, we'll explore the functionality of the workflow and identify processes that may need to be adjusted or customised. While nf-core pipelines are designed to run with 'sensible' default settings, these may not always suit the needs of your experiment of compute environment. Designing a custom run command requires you to identify which parameters you need to specify to suit your circumstances and experimental design. In this lesson, we will download an nf-core pipeline, then design and execute a customised run command using various [parameters](https://www.nextflow.io/docs/latest/config.html#scope-params). 

### **2.1.1. Download the pipeline code**

&#x27A4; In this session we are using Singularity containers to manage software installation for all nf-core/rnaseq tools. Confirm the Singularity cache directory we set in the previous session using the `$NXF_SINGULARITY_CACHEDIR` [Nextflow environmental variable](https://www.nextflow.io/docs/latest/config.html#environment-variables): 

```default
echo $NXF_SINGULARITY_CACHEDIR
```
This should match the directory you set in the previous session: 

```default
/home/ubuntu/singularity_cache
```
::: callout-tip
### **Challenge**{.unlisted}

Use the `nf-core download` command to download a local copy of the nf-core/rnaseq workflow that: 

* Downloads pipeline version 3.11.1  
* Outputs the code base to `~/session2/nf-core-rnaseq-3.11.1/`
* Downloads Singularity containers 
* Uses the preset Singluarity cache and does not copy images to the output directory
:::

::: {.callout-caution collapse="true"}
### Solution

As we explored in [Lesson 1.4.3](1.4_users.md#nf-core-download) we can fetch the workflow code base with the following command:

```default
nf-core download rnaseq \
  --revision 3.11.1 \
  --outdir ~/session2/nf-core-rnaseq-3.11.1 \
  --container singularity \
  --compress none \
  --singularity-cache-only
```
:::

The pipeline files and institutional configuration files from [nf-core/configs](https://github.com/nf-core/configs) will be downloaded to `~/session2/nf-core-rnaseq-3.11.1 `. Inside this directory you will see 2 subdirectories. 

&#x27A4; Take a look at the directory structure:

```default
ls -l nf-core-rnaseq-3.11.1/*
```

```default
nf-core-rnaseq-3.11.1/configs:
total 64
-rwxrwxr-x 1 ubuntu ubuntu  1562 Apr  21 09:17 CITATION.cff
-rwxrwxr-x 1 ubuntu ubuntu  1064 Apr  21 09:17 LICENSE
-rwxrwxr-x 1 ubuntu ubuntu 17476 Apr  21 09:17 README.md
drwxrwxr-x 2 ubuntu ubuntu  4096 Apr  21 09:17 bin
drwxrwxr-x 3 ubuntu ubuntu  4096 Apr  21 09:17 conf
-rwxrwxr-x 1 ubuntu ubuntu   204 Apr  21 09:17 configtest.nf
drwxrwxr-x 4 ubuntu ubuntu  4096 Apr  21 09:17 docs
-rwxrwxr-x 1 ubuntu ubuntu    70 Apr  21 09:17 nextflow.config
-rwxrwxr-x 1 ubuntu ubuntu  8249 Apr  21 09:17 nfcore_custom.config
drwxrwxr-x 2 ubuntu ubuntu  4096 Apr  21 09:17 pipeline

nf-core-rnaseq-3.11.1/workflow:
total 216
-rwxrwxr-x 1 ubuntu ubuntu 58889 Apr  21 09:17 CHANGELOG.md
-rwxrwxr-x 1 ubuntu ubuntu  9681 Apr  21 09:17 CITATIONS.md
-rwxrwxr-x 1 ubuntu ubuntu  9078 Apr  21 09:17 CODE_OF_CONDUCT.md
-rwxrwxr-x 1 ubuntu ubuntu  1096 Apr  21 09:17 LICENSE
-rwxrwxr-x 1 ubuntu ubuntu 10002 Apr  21 09:17 README.md
drwxrwxr-x 3 ubuntu ubuntu  4096 Apr  21 09:17 assets
drwxrwxr-x 2 ubuntu ubuntu  4096 Apr  21 09:17 bin
drwxrwxr-x 2 ubuntu ubuntu  4096 Apr  21 09:17 conf
drwxrwxr-x 3 ubuntu ubuntu  4096 Apr  21 09:17 docs
drwxrwxr-x 2 ubuntu ubuntu  4096 Apr  21 09:17 lib
-rwxrwxr-x 1 ubuntu ubuntu  2736 Apr  21 09:17 main.nf
drwxrwxr-x 4 ubuntu ubuntu  4096 Apr  21 09:17 modules
-rwxrwxr-x 1 ubuntu ubuntu 13970 Apr  21 09:17 modules.json
-rwxrwxr-x 1 ubuntu ubuntu 10847 Apr  21 09:17 nextflow.config
-rwxrwxr-x 1 ubuntu ubuntu 42576 Apr  21 09:17 nextflow_schema.json
-rwxrwxr-x 1 ubuntu ubuntu   359 Apr  21 09:17 pyproject.toml
drwxrwxr-x 4 ubuntu ubuntu  4096 Apr  21 09:17 subworkflows
-rwxrwxr-x 1 ubuntu ubuntu  1684 Apr  21 09:17 tower.yml
drwxrwxr-x 2 ubuntu ubuntu  4096 Apr  21 09:17 workflows
```

The public [institutional configs](https://github.com/nf-core/configs) were downloaded to the `configs` directory. The code base for our pipeline will be stored in the `workflow` directory. The files and directories we will be working with in this session are:

|Feature                |Importance                                                         |
|-----------------------|-------------------------------------------------------------------|
|`conf/`                |Contains files default configuration settings and optional profiles that build on global `nextflow.config`settings|
|`main.nf`              |The executable Nextflow script. It calls `workflows/rnaseq.nf`|
|`modules/`             |Contains processes that are used by the workflow. Each process is split into a module with its own `main.nf` file|
|`workflows/rnaseq.nf`  |The complete rnaseq pipeline, containing modules and subworkflows that are connected by channels|

::: {.callout-caution collapse="true"}
### **Alternate installation method**{.unlisted}
In situations where you might not wish to use the nf-core tools utility, download the nf-core/rnaseq source code from it's [GitHub repository](https://github.com/nf-core/rnaseq) with git. 

Clone the nf-core/rnaseq repository:
```default
git clone https://github.com/nf-core/rnaseq.git
```
:no_entry: **BEWARE** :no_entry: this method will download a copy of the pipeline with a different directory name and slightly different structure. If you choose to use this method, you will need to adjust some paths specified in the upcoming lessons accordingly. 
::: 

### **2.1.2. Design your run command**

As we learned in [Lesson 1.3.3](1.3_configure.md#viewing-parameters), all nf-core pipelines have a unique set of pipeline-specific parameters that can be used in conjunction with Nextflow parameters to configure the workflow. Generally, nf-core pipelines can be customised at different levels:

|Level of effect      |Customisation feature                                                        |
|---------------------|-----------------------------------------------------------------------------|
|The workflow         |Where diverging methods are available for a pipeline, you may choose a method to follow  |
|A process            |Where more than one tool is available for a single step, you may choose which to use  |
|A tool               |You may choose to apply specific thresholds or optional flags for a tool |

Resources allocated for a pipeline to run can also be checked using pipeline parameters. You may find that your runs occasionally fail due to a particular step of the pipeline requesting more resources than you have on your system. These parameters act as a cap, to prevent Nextflow submitting a single job requesting resources more than what is available.

Looking at the nf-core/rnaseq pipeline structure provided in the image below, we can see that the developers have:

1. Organised the workflow into 5 stages based on the type of work that is being done
2. Provided a choice of multiple methods and specified defaults
3. Provided a choice of tools for some steps

The structure of the pipeline gives us a sense of the high-level customisation options available to us.

![](../figs/2.1_pipeline-choice.png)

::: callout-tip
### **Challenge**{.unlisted}

Observing the diagram above, which statement is true regarding the choice of alignment and quantification methods provided by the nf-core/rnaseq pipeline?

**A.** The pipeline uses a fixed method for read alignment and quantification.  
**B.** Users can choose between several different methods for read alignment and quantification.   
**C.** The pipeline always performs read alignment and quantification.     
**D.** The choice of alignment and quantification method is determined automatically based on the input data.  
:::

::: {.callout-caution collapse="true"}
### Solution

The correct answer is B. The nf-core/rnaseq pipeline allows users to choose between pseudo-alignment and quantification or several different methods for genome-based read alignment and quantification. 

* A is incorrect because the pipeline is not limited to a single method.   
* C is incorrect because while read alignment and quantification using STAR and Salmon are the default method, users can choose other methods if desired.
* D is also incorrect, as the pipeline only accepts fastq files as input and the choice of alignment and quantification method must be specified by the user.
:::

Users can customise parameters in 3 different ways:

1. Comand line parameters (i.e. `--param_name`)
2. Parameters files (i.e. `-params-file`)
3. Additional process-specific parameters using the `ext.args` variable (See [Lesson 2.5](2.5_extArgs.qmd))

While all nf-core pipelines are provided with comprehensive documentation that explains workflow structure, process outputs, and available parameters, it can be challenging to piece these different sources of information together to determine which parameters you should be using.

We recommend the following approach to deciding on which parameters to use: 

1. Read the pipeline's [Usage docs](https://nf-co.re/rnaseq/3.11.1/usage) to understand required inputs, workflow structure, and available customisation options.
2. Read the pipeline's [Output docs](https://nf-co.re/rnaseq/3.11.1/output) to understand which processes are run and which files are output for each process.
3. Read the pipeline's [Parameter docs](https://nf-co.re/rnaseq/3.11.1/parameters) to understand all provided parameters for the pipeline. 
4. Check the original documentation of any tools you wish to customise for any additional parameters you may wish to apply. 
5. Ask yourself the following questions:

![](../figs/2.1_chooseParams.png)

::: callout-tip
### How do I know if `ext.args` is used by a process?
The inclusion of `ext.args` is currently standard practice for all DSL2 [nf-core modules](https://nf-co.re/developers/modules) where additional parameters may be required to run a process. However, this may not be implemented for all processes. Depending on the pipeline, some modules may not have defined the `ext.args` variable in the script blocks and is thus not available for applying customisation. 

Take a look at what is available for the nf-core/rnaseq pipeline:

```default
grep -r "ext.args" nf-core-rnaseq-3.11.1/workflow/modules/
```
:::

The number and type of default and optional parameters an nf-core pipeline accepts is at the discretion of it's developers. However, at a minimum, nf-core pipelines typically:

* Require users to specify a [sample sheet](https://nf-co.re/rnaseq/3.11.1/usage#samplesheet-input)  (`--input`) detailing sample data and relevant metadata
* Autogenerate or acquire missing reference files from [iGenomes](https://github.com/nf-core/rnaseq/blob/master/conf/igenomes.config) (using the `--genome` option) if not provided by the user.

&#x27A4; You can see the recommended (typical) run command and all the parameters available for the nf-core/rnaseq pipeline by running:

```default
nextflow run nf-core-rnaseq-3.11.1/workflow/main.nf --help 
```

::: callout-important

### **Beware the hidden parameters!**
Notice the message at the bottom of the screen: 

```default
!! Hiding 24 params, use --show_hidden_params to show them !!
```
Keep in mind that both this help command and the nf-core parameters documentation hides less common parameters. 

::: 

The typical or recommended run command for this pipeline is provided at the top of the screen: 

```default
nextflow run nf-core/rnaseq --input samplesheet.csv --outdir <OUTDIR> --genome GRCh37 -profile docker
```

It outlines a requirement for a few basic things: 

* An input samplesheet 
* A location to store outputs 
* Relevant reference data 
* A software management method

::: {.callout-important}
### **Reminder: hyphens matter in Nextflow!**
Nextflow options use one (`-`) hyphen, whereas pipeline-specific parameters use two (`--`). In the typical run command above `-profile` is a **Nextflow** option, while `--input` is an **nf-core** parameter.
::: 

Most of us will need to adjust the command a little more for our experiments though. Today we'll be adjusting the typical nf-core/rnaseq run command by: 

1. Providing our own sample sheet
2. Using the Singularity profile, instead of the Docker profile
3. Customising the execution of some processes 
4. Specifying the computing resource limitations of our instances 

&#x27A4; Our input fastq files (`fastqs/`), reference data (`mm10_reference/`), and full sample sheet are already available on an external file system called CernVM-FS that we can access from our Nimbus instances. Take a look at the files: 

```default
ls -l /cvmfs/data.biocommons.aarnet.edu.au/training_materials/SIH_training/UnlockNfcore_0523
```

```default
drwxrwxr-x 2 ubuntu ubuntu 4096 Feb 14 05:36 fastqs
drwxrwxr-x 3 ubuntu ubuntu 4096 Feb 14 05:46 mm10_reference
-rw-rw-r-- 1 ubuntu ubuntu  641 Feb 16 05:57 samplesheet.csv
```

&#x27A4; Our CVMFS path is very long, for the sake of tidiness, store the CVMFS path in a variable for our run command:

```default
materials=/cvmfs/data.biocommons.aarnet.edu.au/training_materials/SIH_training/UnlockNfcore_0523
```

::: callout-tip
### **Challenge**{.unlisted}

Using the `nextflow run` command, identify which parameters and files we will need to use to provide our prepared fasta and gtf files, as well as STAR and Salmon index directories to the pipeline.
:::

::: {.callout-caution collapse="true"}
### Solution

Run the following command: 

```default
nextflow run nf-core-rnaseq-3.11.1/workflow/main.nf --help
```
In the reference genome options section are the following flags: 

* `--fasta $materials/mm10_reference/mm10_chr18.fa`  
* `--gtf $materials/mm10_reference/mm10_chr18.gtf`
* `--star_index $materials/mm10_reference/STAR`
* `--salmon_index $materials/mm10_reference/salmon-index`
:::

&#x27A4; Given we are only testing the pipeline in this session, we only need to work with a couple of samples. Copy the first two samples from the full prepared sample sheet to a local version of the file:

```default
head -n 3 $materials/samplesheet.csv > samplesheet.csv
```

```default
sample,fastq_1,fastq_2,strandedness
SRR3473989,/cvmfs/data.biocommons.aarnet.edu.au/training_materials/SIH_training/UnlockNfcore_0523/fastqs/SRR3473989_selected.fastq.gz,,forward
SRR3473988,/cvmfs/data.biocommons.aarnet.edu.au/training_materials/SIH_training/UnlockNfcore_0523/fastqs/SRR3473988_selected.fastq.gz,,forward
```
Now that we have prepared our input data, we will customise the typical run command by:

1. Providing our own reference fasta, index files, and gtf using [file-specific parameters](https://nf-co.re/rnaseq/3.11.1/parameters#reference-genome-options) instead of using the Illumina AWS iGenomes database parameter `--genome`
2. Using Nextflow's `-profile` parameter to specify that we will be running the Singularity profile as [specified in `nextflow.config`](https://github.com/nf-core/rnaseq/blob/3.11.1/nextflow.config#L144) instead of the Docker profile
3. Adding additional process-specific flags to [skip duplicate read marking](https://nf-co.re/rnaseq/3.11.1/parameters#skip_markduplicates), [save trimmed reads](https://nf-co.re/rnaseq/3.11.1/parameters#save_trimmed) and [save unaligned reads](https://nf-co.re/rnaseq/3.11.1/parameters#save_unaligned)
4. Adding additional max resource flags to specify the [number of CPUs](https://nf-co.re/rnaseq/3.11.1/parameters#max_cpus) and [amount of memory](https://nf-co.re/rnaseq/3.11.1/parameters#max_memory) available to the pipeline 

You can see how we've customised the typical run command in the diagram below: 

![](../figs/2.1_default-command.png)

### **2.1.3. Run the pipeline**

&#x27A4; Now that we have prepared our data and chosen which parameters to apply, run the pipeline: 

```default
nextflow run nf-core-rnaseq-3.11.1/workflow/main.nf \
    --input samplesheet.csv \
    --outdir Lesson-2.1 \
    --fasta $materials/mm10_reference/mm10_chr18.fa \
    --gtf $materials/mm10_reference/mm10_chr18.gtf \
    --star_index $materials/mm10_reference/STAR \
    --salmon_index $materials/mm10_reference/salmon-index \
    -profile singularity \
    --skip_markduplicates \
    --save_trimmed true \
    --save_unaligned true \
    --max_memory '6.GB' \
    --max_cpus 2
```

Take a look at the stdout printed to the screen. Your workflow configuration and parameter customisations are all documented here. You can use this to confirm if your parameters have been correctly passed to the run command: 

![](../figs/2.1_nf-core-stdout.png)

As the workflow starts, you will also see a number of processes spawn out underneath this. Recall from [Lession 1.1](1.1_nextflow.md#what-is-nextflow) that processes are executed independently and can run in parallel. Nextflow manages the data dependencies between processes, ensuring that each process is executed only when its input data is available and all of its dependencies have been satisfied. 

To understand how this is coordinated, consider the STAR_ALIGN process that is being run. You'll notice a few things: 

* We can see which inputs are being worked on by a process by looking at the round brackets at the end of the process name
* When a process starts it progressively spawns tasks for all inputs. For some processes this is a single input, for others it is multiple inputs (i.e. samples)
* A number of processes involving reference files and the samplesheet are completed before STAR_ALIGN begins  
* A single TRIMGALORE process is run across both samples in our `samplesheet.csv` before STAR_ALIGN begins 
* Once a TRIMGALORE task is completed for a sample, the STAR_ALIGN task for that sample begins 
* When the STAR_ALIGN process starts, it spawns 2 tasks.
Take a look at the image below which explains a workflow's process status output provided by Nextflow using the data dependencies for the STAR_ALIGN process as an example. 

![](../figs/2.1_nf-core_processes.png)

### **2.1.4. Examine the outputs**

Once your pipeline has completed, you should see this message printed to your terminal:

```default
-[nf-core/rnaseq] Pipeline completed successfully with skipped sampl(es)-
-[nf-core/rnaseq] Please check MultiQC report: 2/2 samples failed strandedness check.-
Completed at: 21-Apr-2023 03:58:56
Duration    : 9m 16s
CPU hours   : 0.3
Succeeded   : 66
```

The pipeline ran successfully, however, note the warning about all samples having failed the strandedness check. We'll explore that in the next lesson. 

&#x27A4; In the meantime, list (`ls -la`) the contents of your directory, you'll see a few new directories (and a hidden directory and log file) have been created:

```default
total 416
drwxrwxr-x   7 ubuntu ubuntu 4.0K Apr 21 03:44 .
drwxr-x---  15 ubuntu ubuntu 4.0K Apr 21 01:56 ..
drwxrwxr-x   4 ubuntu ubuntu 4.0K Apr 21 03:58 .nextflow
-rw-rw-r--   1 ubuntu ubuntu 371K Apr 21 03:58 .nextflow.log
-rw-rw-r--   1 ubuntu ubuntu  17K Apr 21 03:50 .nextflow.log.1
drwxrwxr-x   7 ubuntu ubuntu 4.0K Apr 21 03:58 Lesson-2.1
drwxrwxr-x   4 ubuntu ubuntu 4.0K Apr 21 02:08 nf-core-rnaseq-3.11.1
-rw-rw-r--   1 ubuntu ubuntu  563 Apr 21 03:14 samplesheet.csv
drwxrwxr-x 143 ubuntu ubuntu 4.0K Apr 21 03:58 work
```

Nextflow has created 2 new output directories, **work** and **Lesson-2.1** in the current directory. 

#### The `work` directory

As each job is run, a unique sub-directory is created in the `work` directory. These directories house temporary files and various command logs created by a process. We can find all information regarding this process that we need to troubleshoot a failed process. 

#### The `Lesson-2.1` directory

All final outputs will be presented in a directory specified by the `--outdir` flag. 

#### The `.nextflow` directory

This directory contains a `cache` subdirectory to store cached data such as downloaded files and can be used to speed up subsequent pipeline runs. It also contains a `history` file which contains a record of pipeline executions including run time, the unique run name, and command line arguments used. 

#### The `.nextflow.log` file

This file is created by Nextflow during the execution of a pipeline and contains information about all processes and any warnings or errors that occurred during execution. 

::: callout-tip
### **Challenge**{.unlisted}

Was the runtime for the STAR_ALIGN process comparable for samples SRR3473988 and SRR3473989? 

:bulb: Hint: use the `nextflow log <run_name> -f` command and Nextflow [trace fields](https://www.nextflow.io/docs/latest/tracing.html#trace-report). 
:::

::: {.callout-caution collapse="true"}
### Solution

Run the following: 
```default
nextflow log <run_name> -f name,realtime | grep "STAR_ALIGN" 
```

Read alignment was comparable for both samples:
```default
NFCORE_RNASEQ:RNASEQ:ALIGN_STAR:STAR_ALIGN (SRR3473989) 2m 37s
NFCORE_RNASEQ:RNASEQ:ALIGN_STAR:STAR_ALIGN (SRR3473988) 2m 17s
```
:::

::: {.callout-note}
### **Key points**
- nf-core pipelines are provided with sensible default settings and required inputs. 
- An nf-core pipeline's Usage, Output, and Parameters documentation can be used to design a suitable run command. 
- Parameters can be used to customise the workflow, processes, tools, and compute resources.  
:::