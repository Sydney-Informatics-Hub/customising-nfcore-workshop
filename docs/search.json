[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Reproducible workflows with nf-core",
    "section": "",
    "text": "This course is currently under development\nThis workshop will set you up with the foundational knowledge required to run and customise nf-core workflows in a reproducible manner. Using the nf-core/rnaseq workflow as an example, we will step through essential features common across all nf-core workflows. We will explore ways to adjust the workflow parameters based on the needs of your dataset and configuration the workflow to run on your computational environment.\n\nTrainers\n\nCali Willet, Sydney Informatics Hub\nChris Hakkaart, Seqera Labs\nGeorgie Samaha, Sydney Informatics Hub\n\n\n\nTarget audience\nThis workshop is suitable for people who are familiar with working at the command line interface and have some experience running nf-core workflows.\n\n\nPrerequisites\n\nExperience navigating the Unix command line\nFamiliarity with Nextflow and nf-core workflows\n\n\n\nSet up requirements\nPlease complete the Setup Instructions before the course.\nIf you have any trouble, please get in contact with us ASAP.\n\n\nCode of Conduct\nWe expect all attendees of our training to follow our code of conduct, including bullying, harassment and discrimination prevention policies.\nIn order to foster a positive and professional learning environment we encourage the following kinds of behaviours at all our events and on our platforms:\n\nUse welcoming and inclusive language\nBe respectful of different viewpoints and experiences\nGracefully accept constructive criticism\nFocus on what is best for the community\nShow courtesy and respect towards other community members\n\nOur full CoC, with incident reporting guidelines, is available here.\n\n\nWorkshop schedule\n\n\n\nLesson\nOverview\n\n\n\n\nSet up your computer\nFollow these instructions to install VSCode and login to your Nimbus instance.\n\n\nDay 1: Introduction to nf-core\n\n\n\nDay 2: Customising nf-core\n\n\n\n\n\n\nCourse survey\nPlease fill out our course survey before you leave! Help us help you! üòÅ\n\n\nCredits and acknowledgements\nThis workshop event and accompanying materials were developed by the Sydney Informatics Hub, University of Sydney in partnership with Seqera Labs, Pawsey Supercomputing Research Centre, and Australia‚Äôs National Research Education Network (AARNet) enabled through the Australian BioCommons (NCRIS via Bioplatforms Australia).\n\n\n\n\nAll materials copyright Sydney Informatics Hub, University of Sydney"
  },
  {
    "objectID": "tips_tricks.html",
    "href": "tips_tricks.html",
    "title": "Some tips and tricks",
    "section": "",
    "text": "All materials copyright Sydney Informatics Hub, University of Sydney"
  },
  {
    "objectID": "setup.html",
    "href": "setup.html",
    "title": "Set up your computer",
    "section": "",
    "text": "Questions\n\nHow do I install a terminal or IDE application on my computer?\nHow do I log in to a Nimbus instance?\n\n\nIn this workshop series, we will be using Pawsey‚Äôs Nimbus cloud. The Pawsey Supercomputing Research Centre is one of two, Tier-1, High Performance Computing facilities in Australia. Their Nimbus cloud platform is an accessible and flexible solution for bioinformatics applications that may not be suitable for large-scale HPC machines including:\n\nDeveloping and refining scalable workflows in prepration for HPC allocation applications.\nWorkflows with long runtimes that excede wall time queue limits on HPC facilities.\nComplex data-bound workflows with variable compute resource profiles that are common in bioinformatics pipelines.\n\nThe main requirements for this workshop are a personal computer with:\n\nA web broswer\nTerminal or IDE application\n\nOn this page you will find instructions on how to set up a terminal application and web browser on your computer and how to connect to Nimbus. Each participant will be provided with their instance‚Äôs IP address at the beginning of the workshop.\nTo connect to your Nimbus instance, you will need either a terminal or integrated development environment (IDE) application installed on your computer. While we recommend you use the Visual Studio Code IDE for this workshop, we have also provided directions for installing and using a terminal applications below.\n\nInstall and set up Visual Studio Code\nVisual Studio Code is a lightweight and powerful source code editor available for Windows, macOS and Linux computers.\n\nDownload Visual Studio Code for your system from here and follow the instructions for:\n\nmacOS\nLinux\nWindows\n\nOpen the VS Code application on your computer\n\n\n\nClick on the extensions button (four blocks) on the left side bar and install the remote SSH extension. Click on the blue install button.\n\n\n\nLogin via Visual Studio Code\n\nConnect to your instance with VS code by adding the host details to your ssh config file.\n\nCtrl+Shift+P to open command palette\nSelect Remote-SSH: Open SSH configuraiton file\nAdd new entry, filling out host name and identity file:\n\nHost nfcoreWorkshop\n  HostName 146.118.XX.XXX  \n  User training     \nConnect to this address\n\nCtrl+Shift+P to open command palette\nSelect Remote-SSH: Connect to Host and select name of your host\nSelect Linux from dropdown menu and then continue\n\n\n\n\n\nInstall and set up a terminal application\nThe terminal applications available to you will depend on your operating system.\n\nLinux terminals\nIf you use Linux, chances are you already know your shell and how to use it. Basically, just open your preferred terminal program and off you go!\n\n\nOS X (Mac)\nMac operating systems come with a terminal program, called Terminal. Just look for it in your Applications folder, or hit Command + Space and type ‚Äòterminal‚Äô. You may find that other, 3rd party terminal programs are more user-friendly and powerful, like Iterm2.\n\n\nWindows\nWe recommend MobaXterm, which offers a rich experience as a full-featured X-server and terminal emulator for ssh connections, the free version is more than adequate.\nTo install and start using MobaXterm:\n\nGo to https://mobaxterm.mobatek.net/download.html\nUnder ‚ÄòHome Edition‚Äô select the Download now button\nSelect the MobaXterm Home Edition (Installer edition)\nOnce the program is downloaded, install it as you would any other windows program\nOnce the program is installed, start the MobaXterm program\nFrom this screen, click on ‚Äòstart local terminal‚Äô (and install Cygwin if prompted)\n\n\n\n\nLogin via Terminal\nTo log in to Nimbus, we will use a Secure Shell (SSH) connection. To connect, you need 3 things: 1. The assigned IP address of your instance (i.e.¬†###.###.##.###). Each participant will be provided with their instance‚Äôs IP address at the beginning of the workshop. 2. Your login name. In our case, this will be training for all participants. 3. Your password. All participants will be provided with a password at the beginning of the workshop.\nTo log in, type the following into your terminal, using your login name and the instance‚Äôs IP address:\nssh training@###.###.###.###\nYou will receive a message saying:\nThe authenticity of host 'XXX.XXX.XX.XXX (XXX.XXX.XX.XXX)' can't be established.\nRemember your host address will be different than the one above. There will then be a message saying:\nAre you sure you want to continue connecting (yes/no)?\nIf you would like to skip this message next time you log in, answer ‚Äòyes‚Äô. It will then give a warning:\nWarning: Permanently added 'XXX.XXX.XX.XXX' (ECDSA) to the list of known hosts.\nEnter the password provided at the beginning of the workshop. Ask one of the demonstrators if you‚Äôve forgotten it.\n\n\n\n\n\n\nPay Attention\n\n\n\nWhen you type a password on the terminal, there will not be any indication the password is being entered. You‚Äôll not see a moving cursor, or even any asterisks, or bullets. That is an intentional security mechanism used by all terminal applications and can trip us up sometimes, so be careful when typing or copying your password in.\n\n\nHaving successfully logged in, your terminal should then display something like that shown in the figure below:\n\n\n\n\n\nAll materials copyright Sydney Informatics Hub, University of Sydney"
  },
  {
    "objectID": "notebooks/1.0_intro.html",
    "href": "notebooks/1.0_intro.html",
    "title": "Welcome to session 1",
    "section": "",
    "text": "In this session we will be‚Ä¶\n\n\n\nAll materials copyright Sydney Informatics Hub, University of Sydney"
  },
  {
    "objectID": "notebooks/2.6_troubleshoot.html",
    "href": "notebooks/2.6_troubleshoot.html",
    "title": "Troubleshooting issues and errors",
    "section": "",
    "text": "Objectives\n\n\n\n\n\n\n\nAll materials copyright Sydney Informatics Hub, University of Sydney"
  },
  {
    "objectID": "notebooks/2.1_design.html",
    "href": "notebooks/2.1_design.html",
    "title": "Designing your run command",
    "section": "",
    "text": "::: callout-tip\n\nObjectives\n\nUse the nf-core documentation to select appropriate parameters for a run command\nWrite and run a nf-core rnaseq command on the command line\nExplore workflow deployment and set up :::\n\n\n\nDownload the workflow code\nIt can be very easy to lose track while working on the command line, especially when we‚Äôre working with large datasets and complex commands as we do with bioinformatics workflows. To make sure we work reproducibly, we will be organising our workspace and using a local copy of the nf-core/rnaseq workflow for all exercises.\nStart by creating a new directory for all of today‚Äôs activities and move into it:\nmkdir ~/nfcore-workshop/session2 && cd $_\nThere are a number of ways to download a nf-core workflow to your machine. We recommend using git or nf-core tools. To download the workflow using the nf-core tools utility, read and follow directions here and complete the following exercise:\n\n\n\n\n\n\nChallenge\n\n\n\nWhat command would you run to find and download a copy of the nf-core/rnaseq v3.10.1 workflow using the nf-core tools utility?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nSearch for the rnaseq pipeline:\nnf-core list rnaseq\nThen, download the correct pipeline:\nnf-core download nf-core/rnaseq\nYou will be prompted to select a version. Use your arrow keys to specify 3.10.1 and hit enter.\nubuntu@georgiedev:~$ nf-core download nf-core/rnaseq\n\n                                          ,--./,-.\n          ___     __   __   __   ___     /,-._.--~\\\n    |\\ | |__  __ /  ` /  \\ |__) |__         }  {\n    | \\| |       \\__, \\__/ |  \\ |___     \\`-._,-`-,\n                                          `._,._,'\n\n    nf-core/tools version 2.7.2 - https://nf-co.re\n\n\n? Select release / branch: 3.10.1  [release]\n\nIn addition to the pipeline code, this tool can download software containers.\n? Download software container images: none\n\nIf transferring the downloaded files to another system, it can be convenient to have everything compressed in a single file.\n? Choose compression type: none\nINFO     Saving 'nf-core/rnaseq'\n          Pipeline revision: '3.10.1'\n          Pull containers: 'none'\n          Output directory: 'nf-core-rnaseq-3.10.1'\nINFO     Downloading workflow files from GitHub\nINFO     Downloading centralised configs from GitHub\n\n\n\nAlternatively, to download the most recent version of the workflow from it‚Äôs GitHub repository with git, run:\ngit clone https://github.com/nf-core/rnaseq.git\nCheck the workflow has been downloaded:\nls -l nf-core-rnaseq-3.10.1\nInside your nf-core-rnaseq workflow directory, you should see 2 subdirectories:\ntotal 8\ndrwxrwxr-x  7 ubuntu ubuntu 4096 Mar 24 06:08 configs\ndrwxrwxr-x 12 ubuntu ubuntu 4096 Mar 24 06:08 workflow\n\n\nBuilding your run command\nAll nf-core workflows are provided with sensible default settings that have broad applicability and comprensive documentation that explains all available parameters. What is ‚Äòsensible‚Äô varies dramatically between different experiments, computing environments, and datasets, so these settings might not suit your needs. For this workshop, consider the experimental design below:\n\nWe won‚Äôt run the pseudo alignment step\nWe have chosen to use STAR to align reads\nWe have chosen to use Salmon to estimate transcript abundance\nWe only have access to 2 CPUs and 8Gb of RAM today\nWe are working with our own subset data today (including reference data)\n\n\n\n\n\n\n\n\nChallenge\n\n\n\nUsing the nf-core/rnaseq documentation and the diagram above, can you decide which flags you may need to add to this command for this experiment?\nnextflow run nf-core-rnaseq-3.10.1/workflow/main.nf \\\n  --input &lt;samples.tsv&gt; \\\n  -profile singularity \\\n  -with-report execution_report_exercise2_1.html \\\n  -with-trace execution_trace_exercise2_1.txt \\\n  -with-timeline timeline_exercise2_1.html \\\n  -with-dag dag_exercise2_1.png\nüí° You will need to look at the reference genome, alignment, and max job request options.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nGiven we are using STAR and Salmon as our aligner and quantification tool of choice (respectively) and it is the default choice of this workflow we will not need to provide an --aligner flag. However, if you wanted to provide this for the sake of reproducibility in case things change in the future:\n--aligner 'star_salmon'\nGiven we are providing our own subset data for this workshop, we will need to use:\n--fasta /path/to/mouse.fa\n--gtf /path/to/mouse.gtf\n--star_index /path/to/STAR\nGiven we have limited computing resources today, we will need to specify a ceiling for both memory and CPUs:\n--max_memory '6.GB'\n--max_cpus 2\n\n\n\n\n\n\n\n\n\nZoom reaction check in!\n\n\n\nIs everyone ok?\nüëè (clap) yes, lets move on.\nüò¢ (cry) no, please help.\n\n\n\n\nRun the workflow\nMake a new working directory for this lesson and move into it:\nmkdir ~/nfcore-workshop/session2/exercise1 && cd $_\nFor the sake of expediency, we are using prepared subset data for this session. All the data (including fastqs, input manifest, reference fasta, gtf, and STAR indexes) are available on the CernVM-FS file system. CernVM-FS is a read-only file system that Pawsey have used to store files such as containerised tools (Biocontainers), reference datasets, and other shared resources that are commonly used by many researchers. Take a look here for more information on bioinformatics resources provided by Pawsey on Nimbus.\nTake a quick look at the workshop data we‚Äôre working with today:\nls /path/to/aarnet-cvmfs/training/workshopMaterials\nWe need to store this path in a variable for our run command:\nmaterials=/path/to/aarnet-cvmfs/training/workshopMaterials\nNow run the workflow:\nnextflow run nf-core-rnaseq-3.10.1/workflow/main.nf \\\n  --input $materials/samples.tsv \\\n  -profile singularity \\\n  --fasta $materials/mm10_chr18.fa \\\n  --gtf $materials/mm10_chr18.gtf \\\n  --star_index $materials/STAR \\\n  --max_memory '6 GB' --max_cpus 2 \\\n  --outdir ex1_results \\\n  -with-report execution_report_exercise2_1.html \\\n  -with-trace execution_trace_exercise2_1.txt \\\n  -with-timeline timeline_exercise2_1.html \\\n  -with-dag dag_exercise2_1.png\n\n\nReproducibility is a state of mind\nWe have to wait for the workflow to run (this should take ~17 mins) before we can get on with the other exercises. While we wait, lets discuss how we manage reproducibility in our own practices, and share some useful resources with one another:\n\n\n\nKey points\n\n\n\n\n\n\n\nAll materials copyright Sydney Informatics Hub, University of Sydney"
  },
  {
    "objectID": "notebooks/1.1_nextflow.html",
    "href": "notebooks/1.1_nextflow.html",
    "title": "Introduction to Nextflow",
    "section": "",
    "text": "Nextflow is a workflow orchestration engine and domain-specific language (DSL) that makes it easy to write data-intensive computational workflows.\nIt is designed around the idea that the Linux platform is the lingua franca of data science. Linux provides many simple but powerful command-line and scripting tools that, when chained together, facilitate complex data manipulations.\nNextflow extends this approach, adding the ability to define complex program interactions and a high-level parallel computational environment, based on the dataflow programming model.\nNextflow‚Äôs core features are:\n\nWorkflow portability and reproducibility\nScalability of parallelization and deployment\nIntegration of existing tools, systems, and industry standards\n\nWhether you are working with genomics data or other large and complex data sets, Nextflow can help you to streamline your workflow and improve your productivity.\nAll materials copyright Sydney Informatics Hub, University of Sydney"
  },
  {
    "objectID": "notebooks/1.1_nextflow.html#installing-nextflow",
    "href": "notebooks/1.1_nextflow.html#installing-nextflow",
    "title": "Introduction to Nextflow",
    "section": "Installing Nextflow",
    "text": "Installing Nextflow\nNextflow is distributed as a self-installing package and does not require any special installation procedure. If you do not already have Nextflow available, it can be installed using a few easy steps:\n\nDownload the executable package using either wget -qO- https://get.nextflow.io | bash or curl -s https://get.nextflow.io | bash\nMake the binary executable on your system by running chmod +x nextflow.\nMove the nextflow file to a directory accessible by your $PATH variable, e.g, mv nextflow ~/bin/"
  },
  {
    "objectID": "notebooks/1.1_nextflow.html#nextflow-options-and-commands",
    "href": "notebooks/1.1_nextflow.html#nextflow-options-and-commands",
    "title": "Introduction to Nextflow",
    "section": "Nextflow options and commands",
    "text": "Nextflow options and commands\nNextflow provides a robust command line interface for the management and execution pipelines. The top-level interface consists of options and commands.\nA list of options and commands can be viewed using the -h option:\nnextflow -h\n\n\n\n\n\n\nChallenge\n\n\n\nFind out which version of Nextflow you are using using a Nextflow option.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe version of Nextflow you are using can be printed using the -v option:\nnextflow -v"
  },
  {
    "objectID": "notebooks/1.1_nextflow.html#managing-your-environment",
    "href": "notebooks/1.1_nextflow.html#managing-your-environment",
    "title": "Introduction to Nextflow",
    "section": "Managing your environment",
    "text": "Managing your environment\nYou can control the Nextflow runtime and the underlying Java virtual machine using environment variables. These variables can be exported before running a workflow and will be interpreted as environment variable by Nextflow.\nFor most users, Nextflow will work without setting any environment variables. However, for consistency, it is good practice to pin the version of Nextflow you are using when running a workflow using the NXF_VER variable.\nexport NXF_VER=&lt;version number&gt;\nSimilarly, if you are using a shared resource, you may also consider including paths to where software is stored and can be accessed using the NXF_SINGULARITY_CACHEDIR or the NXF_CONDA_CACHEDIR variables:\nexport NXF_CONDA_CACHEDIR=&lt;custom/path/to/conda/cache&gt;\nYou may want to include these in your .bashrc (or alternate) that is loaded when you log in so you don‚Äôt need to export variables every session.\n\n\n\n\n\n\nChallenge\n\n\n\nTry pinning the version of Nextflow to 22.04.5 using the NXF_VER environmental variable and check that it has been applied.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nExport the version using the NXF_VER environmental variable:\nexport NXF_VER=22.04.5\nCheck that the new version has been applied using the -v option:\nnextflow -v\n\n\n\nA complete list of environmental variables can be found here."
  },
  {
    "objectID": "notebooks/1.1_nextflow.html#executing-a-workflow",
    "href": "notebooks/1.1_nextflow.html#executing-a-workflow",
    "title": "Introduction to Nextflow",
    "section": "Executing a workflow",
    "text": "Executing a workflow\nNextflow seamlessly integrates with code repositories such as GitHub. This feature allows you to manage your project code and use public Nextflow workflows quickly, consistently, and transparently.\nThe Nextflow pull command will download a workflow from a hosting platform into your global cache $HOME/.nextflow/assets folder.\nIf you are pulling a project hosted in a remote code repository, you can specify its qualified name or the repository URL. The qualified name is formed by two parts - the owner name and the repository name separated by a / character. For example, if a Nextflow project foo is hosted in a GitHub repository bar at the address http://github.com/foo/bar, it could be pulled using:\nnextflow pull foo/bar\nOr by using the complete URL:\nnextflow pull http://github.com/foo/bar\nAlternatively, the Nextflow clone command can be used to download a workflow into a local directory of your choice:\nnextflow clone foo/bar &lt;your/path&gt;\nThe Nextflow run command is used to initiate the execution of a workflow script.\nnextflow run foo/bar\nWhen you run a workflow, it will look for a local file with the workflow name you‚Äôve specified. If that file does not exist, it will look for a public repository with the same name on GitHub (unless otherwise specified). If it is found, Nextflow will automatically pull the workflow to your global cache and execute it.\n\n\n\n\n\n\nChallenge\n\n\n\nTry running the hello workflow directly from nextflow-io GitHub.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nRun the nextflow-io/hello workflow:\nnextflow run nextflow-io/hello\n\n\n\nA full list of run options can be found here."
  },
  {
    "objectID": "notebooks/1.1_nextflow.html#executing-a-revision",
    "href": "notebooks/1.1_nextflow.html#executing-a-revision",
    "title": "Introduction to Nextflow",
    "section": "Executing a revision",
    "text": "Executing a revision\nWhen a Nextflow workflow is created or updated, a new revision is created. Each revision is identified by a unique number, which can be used to track changes made to the workflow and to ensure that the same version of the workflow is used consistently across different runs.\nThe Nextflow info command can be used to view workflow properties, such as the project name, repository, local path, main script, and revisions. The * indicates which revision of the pipeline you have stickied and will be executed when using the run command.\nnextflow info nextflow-io/hello\nTo use a specific revision, you simply need to add it to the command line with the --revision or -r flag. For example, to run a workflow with revision v1.0, you would use the following command:\nnextflow run &lt;pipeline&gt; -r v1.0\nNextflow provides built-in support for version control using Git, which allows users to easily manage and track changes made to a workflow over time. A revision can be a git branch, tag or commit SHA number.\n\n\n\n\n\n\nChallenge\n\n\n\nTry running hello workflow again using the v1.1 revision tag.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nRun the nextflow-io/hello workflow with the revision flag:\nnextflow run nextflow-io/hello -r v1.1\n\n\n\nIf your local version of a workflow is not the latest you be shown a warning and will be required to use a revision flag when executing the workflow."
  },
  {
    "objectID": "notebooks/1.1_nextflow.html#listing-and-dropping-workflows",
    "href": "notebooks/1.1_nextflow.html#listing-and-dropping-workflows",
    "title": "Introduction to Nextflow",
    "section": "Listing and dropping workflows",
    "text": "Listing and dropping workflows\nOver time you might want to remove or update your stored workflows. Nextflow also has functionality to help you to view and remove workflows that have been pulled locally.\nThe Nextflow list command prints the projects stored in your global cache $HOME/.nextflow/assets. These are the workflows that were pulled when you executed either of the Nextflow pull or run commands:\nnextflow list\nIf you want to remove a workflow from your cache you can remove it using the Nextflow drop command:\nnextflow drop &lt;workflow&gt;\n\n\n\n\n\n\nChallenge\n\n\n\nSee which workflows you have stored and them with the drop command.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nList your workflow assets:\nnextflow list\nDrop the nextflow-io/hello workflow:\nnextflow drop nextflow-io/hello\nCheck it has been removed:\nnextflow list\n\n\n\n\n\n\n\n\n\nKey points\n\n\n\n\nNextflow is a workflow orchestration engine and domain-specific language (DSL) that makes it easy to write data-intensive computational workflows.\nEnvironment variables can be used to control your Nextflow runtime and the underlying Java virtual machine.\nThe pull, run, and clone commands can be used to download and store Nextflow workflows.\nThe list and drop commands can be used to view and remove local workflows."
  },
  {
    "objectID": "notebooks/1.4_users.html",
    "href": "notebooks/1.4_users.html",
    "title": "nf-core for users",
    "section": "",
    "text": "Commands for users\n\nnf-core list\nThere are currently 80 workflows (March 2023) available as part of nf-core. These workflows are at various stages of development with 49 released, 19 under development, and 12 archived. The list of available workflows, as well as their documentation, can be explored on the nf-core website.\nThe nf-core list command can also be used to list the available nf-core workflows along with local information.\n\n\n\n\n\n\nChallenge\n\n\n\nTry to find out which workflows are available and if you have any locally:\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nRun the list command to see what workflows are available.\nnf-core list\n\n\n\nThe output shows the latest workflow version number and when that was released. It also tells you if and when a workflow was been pulled locally and whether you have the latest version.\nUnless you are actively developing workflow code, you can use Nextflow‚Äôs built-in functionality to fetch nf-core workflows. You can use the Nextflow pull command to download the latest version of a remote workflow from the nf-core GitHub repository:\nnextflow pull nf-core/&lt;workflow&gt;\nNextflow can also fetch the workflow code when you run it without pulling the workflow beforehand:\nnextflow run nf-core/&lt;workflow&gt;\n\nNextflow will fetch the default git branch if a workflow version is not specified. This will be the master branch for workflows with a stable release.\n\nnf-core workflows use GitHub releases to tag stable versions of the code and software. You will always be able to run a previous version of a workflow once it is released.\n\n\n\n\n\n\nChallenge\n\n\n\nTry to pull the latest version of the nf-core/rnaseq workflow directly from GitHub using Nextflow and check what version you have locally.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nUse nextflow pull to download the rnaseq workflow from the nf-core GitHub repository.\nnextflow pull nf-core/rnaseq\nUse nf-core list to view what version of the workflow you have locally\nnf-core list\n\n\n\n\n\nnf-core launch\nNextflow workflows can have a considerable number of optional command line flags. To help manage these, you can use the nf-core launch command.\nThe command takes one argument - either the name of an nf-core workflow which will be pulled automatically or the path to a directory containing a Nextflow workflow. For example:\nnf-core launch nf-core/&lt;workflow name&gt;\nWhen running this command, you will first be asked about which version of a workflow you would like to run. Next, you will be given the choice between a web-based graphical interface or an interactive command-line wizard tool to enter the workflow parameters for your run. Both interfaces show documentation alongside each parameter and validate your inputs.\nThe tool uses the nextflow_schema.json file from a workflow to give parameter descriptions, defaults, and grouping. If no file for the workflow is found, one will be automatically generated at runtime.\nNextflow parameter variables are saved into a JSON file called nf-params.json and used by Nextflow with the -params-file flag.\nThe wizard will ask if you want to launch the Nextflow run. You will also be given the run command and a copy of the JSON file for you to copy and paste if you wish.\n\n\nnf-core download\nSometimes you may need to run an nf-core workflow on a server or HPC system that has no internet connection. In this case, you will need to fetch the workflow files and manually transfer them to your system.\nTo make this process easier and ensure accurate retrieval of correctly versioned code and software containers, nf-core has a download helper tool.\nThe nf-core download command will download both the workflow code and the institutional nf-core/configs files. It can also optionally download singularity image file.\nnf-core download\nIf run without any arguments, the download tool will interactively prompt you for the required information. Each prompt option has a flag and if all flags are supplied then it will run without a request for any additional user input.\n\n\n\n\nAll materials copyright Sydney Informatics Hub, University of Sydney"
  },
  {
    "objectID": "notebooks/2.4_multiConfig.html",
    "href": "notebooks/2.4_multiConfig.html",
    "title": "Using multiple configuration files at once",
    "section": "",
    "text": "Objectives\n\nUnderstand the heirarchy of configuration files specified by Nextflow\nWrite a custom configuration file for MultiQC in the YAML file format\n\n\n\n\n\nAll materials copyright Sydney Informatics Hub, University of Sydney"
  },
  {
    "objectID": "notebooks/2.2_params.html",
    "href": "notebooks/2.2_params.html",
    "title": "Using a params file",
    "section": "",
    "text": "Objectives\n\nWrite a parameter file in the YAML file format\nRun a workflow using a parameters file and appropriate Nextflow flag\nUnderstand the value of using a parameter file for reproducibility\nObserve the behaviour of Nextflow‚Äôs cache functionality\n\n\n\n\n\nAll materials copyright Sydney Informatics Hub, University of Sydney"
  },
  {
    "objectID": "notebooks/2.3_configEnv.html",
    "href": "notebooks/2.3_configEnv.html",
    "title": "Configuring a run for your environment",
    "section": "",
    "text": "Objectives\n\nUnderstand formatting requirements of a config file\nWrite a custom config file for your local environment that overwrites default workflow settings\nRun a workflow using the custom config file and appropriate Nextflow flag\nUse an alternative container source for a workflow process\n\n\n\n\n\nAll materials copyright Sydney Informatics Hub, University of Sydney"
  },
  {
    "objectID": "notebooks/2.5_extArgs.html",
    "href": "notebooks/2.5_extArgs.html",
    "title": "Specifying external arguments to a process",
    "section": "",
    "text": "Objectives\n\nUnderstand how to use the ext.args feature to pass additional command-line arguments to a process\nImplement additional external arguments to a process that are not hardcoded in the process script\nWrite a custom configuration file for MultiQC in the YAML file format\nObserve the behaviour of Nextflow‚Äôs cache functionality\n\n\n\n\n\nAll materials copyright Sydney Informatics Hub, University of Sydney"
  },
  {
    "objectID": "notebooks/2.0_intro.html",
    "href": "notebooks/2.0_intro.html",
    "title": "Welcome to session 2",
    "section": "",
    "text": "In this session we will be writing, running, adjusting, and rerunning the nf-core/rnaseq workflow run command as we step through various customisation scenarios. While all activities in this session will be performed using the nf-core/rnaseq workflow, all customisation scenarios we explore are applicable to other nf-core workflows and do not require an understanding of rnaseq data processing.\n\nThings to keep in mind\nBefore starting this session, we should discuss some important considerations and recommendations to keep in mind as you proceed through the lessons and apply these techniques to your own research. As with all open source bioinformatics resources, nf-core workflows may not suit all applications. It is important that you understand the needs of your dataset and research questions before deciding on a workflow.\n\n\n\nLog back in to your instance\n\nIn Visual Studio Code\nSame as yesterday, connect to your instance using the command palatte:\n\nCtrl+Shift+P to open command palette\nSelect Remote-SSH: Connect to Host and select name of your host\nSelect Linux from dropdown menu and then continue\n\nHaving successfully logged in, you should see a small green box in the bottom left corner of your screen:\n\n\n\nIn a terminal\nWith a terminal application, run the following on the command-line:\nssh training@###.###.###.###\nEnter the password provided at the beginning of the workshop. Ask one of the demonstrators if you‚Äôve forgotten it.\nEnter password:\nHaving successfully logged in, your terminal should then display something like that shown in the figure below:\n\n\n\n\nKey points\n\n\n\n\n\n\n\nAll materials copyright Sydney Informatics Hub, University of Sydney"
  },
  {
    "objectID": "notebooks/1.3_configure.html",
    "href": "notebooks/1.3_configure.html",
    "title": "Configuring pipelines",
    "section": "",
    "text": "nf-core pipelines follow a set of best practices and standardized conventions. The structure of an nf-core pipeline is designed to be modular, easily customizable, and reproducible. Although you won‚Äôt need to edit the code base to run an nf-core pipeline, having a basic understanding of the repository structure will help you understand how to configure its execution.\n\nnf-core pipeline structure\nnf-core pipelines start from a common template and follow the same structure.\n\n\n\nConfiguration\nWhen a pipeline script is launched, Nextflow will look for configuration files in multiple locations. As each configuration file can contain conflicting settings, the sources are ranked to decide which settings to are applied.\nConfiguration sources are reported below and listed in order of priority:\n\nParameters specified on the command line (--something value)\nParameters provided using the -params-file option\nConfig file specified using the -c my_config option\nThe config file named nextflow.config in the current directory\nThe config file named nextflow.config in the workflow project directory\nThe config file $HOME/.nextflow/config\nValues defined within the pipeline script itself (e.g., main.nf)\n\n\n\n\n\n\n\nWarning\n\n\n\nA --params-file must be used to define parameters.\nParameters defined in the parameter block in custom.config files WILL NOT override defaults in nextflow.config for nf-core pipelines.\n\n\n\n\nnextflow.config\nFor nf-core pipelines, the nextflow.config contains parameter defaults. Inside the nextflow.config several includeConfig statements are used to include additional .config files from the conf/ folder.\n\nbase.config\n\nGenerous resource allocations using labels.\n\nigenomes.config\n\nDefault configuration to assess AWS iGenomes.\n\nmodules.config\n\nModule-specific configuration options (both mandatory or optional).\n\ntest.config\n\nA configuration to test the pipeline with a small test dataset\n\ntest_full.config\n\nA configuration to test the pipeline with a full-size test dataset.\n\n\n\n\nConfig profiles\nConfiguration files can also contain the definition of one or more profiles. A profile is a set of configuration attributes that can be activated when launching a pipeline by using the -profile command line option.\nConfiguration profiles are defined by using the special scope profiles which group the attributes that belong to the same profile using a common prefix. For example, profiles defined in you your nextflow.config might like like:\nprofiles {\n\n    standard {\n        process.executor = 'local'\n    }\n\n    cluster {\n        process.executor = 'sge'\n        process.queue = 'long'\n        process.memory = '10GB'\n    }\n\n}\nnextflow run &lt;your script&gt; -profile standard\nAdditionally, includeConfig are used to access custom institutional profiles for different institutions that have been submitted to the nf-core repository on GitHub.\nMORE INFO + LINK\n\n\n\n\nAll materials copyright Sydney Informatics Hub, University of Sydney"
  },
  {
    "objectID": "notebooks/0.0_template.html",
    "href": "notebooks/0.0_template.html",
    "title": "Lesson title",
    "section": "",
    "text": "::: {.callout-note}\n\nLearning objectives\n\nlearning outcome 1\nlearning outcome 2 :::\n\nSome intro text to what this lesson is about\n\n\nSub-section heading\nCommands should be written like this:\ncommand\nWhere relevant include expected standard output:\nstdout here\nAny important notes for attendees should be present in information boxes. For example:\n\n\n\n\n\n\nCopying the code from the grey boxes on training materials\n\n\n\nIn this workshop we need to copy code from the grey boxes in the training materials and run it in the terminal. If you hover your mouse over a grey box on the website, a clipboard icon will appear on the right side. Click on the clipboard logo to copy the code. Test it out with:\nssh training@###.###.###.###\n\n\nChallenges/activites should be provided in challenge boxes:\n\n\n\n\n\n\nChallenge\n\n\n\nQuestion or activity\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nSolution explanation and code where relevant\n\n\n\n\nFor other types of callout blocks see here. Any figures should be placed in figs directory and embeddeded like this: \n::: {.callout-note}\n\n\nKey points\n\ntakeaway 1\ntakeaway 2 :::\n\n\n\n\n\nAll materials copyright Sydney Informatics Hub, University of Sydney"
  },
  {
    "objectID": "notebooks/1.2_nfcore.html",
    "href": "notebooks/1.2_nfcore.html",
    "title": "Introduction to nf-core",
    "section": "",
    "text": "nf-core is a community effort to collect a curated set of analysis workflows built using Nextflow.\nnf-core provides a standardized set of best practices, guidelines, and templates for building and sharing bioinformatics workflows. These workflows are designed to be modular, scalable, and portable, allowing researchers to easily adapt and run them on their own data and compute resources.\nThe nf-core community comprises a diverse group of bioinformaticians, developers, and researchers from around the world who collaborate on developing and maintaining a growing collection of high-quality workflows. These workflows cover a range of applications, including transcriptomics, proteomics, and metagenomics.\nOne of the key benefits of nf-core is that it promotes open development, testing, and peer review, ensuring that the workflows are robust, well-documented, and validated against real-world datasets. This helps to increase the reliability and reproducibility of bioinformatics analyses and ultimately enables researchers to accelerate their scientific discoveries.\nnf-core is published in Nature Biotechnology! Nat Biotechnol 38, 276‚Äì278 (2020). Nature Biotechnology\n\n\nDocumentation\nnf-core workflows have extensive documentation covering installation, usage, and description of output files to ensure that you won‚Äôt be left in the dark.\n\nCI Testing\n\nEvery time a change is made to the workflow code, nf-core workflows use continuous-integration testing to ensure that nothing has broken.\n\nStable Releases\n\nnf-core workflows use GitHub releases to tag stable versions of the code and software, making workflow runs totally reproducible.\n\nPackaged software\n\nPipeline dependencies are automatically downloaded and handled using Docker, Singularity, Conda, or other software management tools. There is no need for any software installations.\n\nPortable and reproducible\n\nnf-core workflows follow best practices to ensure maximum portability and reproducibility. The large community makes the workflows exceptionally well-tested and easy to run.\n\nCloud-ready\n\nnf-core workflows are tested on AWS after every major release. You can even browse results live on the website and use outputs for your own benchmarking.\n\n\nAll nf-core workflows are open-source and community driven.\n\n\n\nnf-core events are community-driven gatherings that provide a platform to discuss the latest developments in Nextflow and nf-core workflows. These events typically include a combination of community seminars, trainings, and hackathons, and are open to anyone who is interested in using and developing nf-core and its applications. Most events are held virtually, making them accessible to a global audience.\nUpcoming events are listed on the nf-core event page and announced on Slack and Twitter.\n\n\n\nThere are several ways you can join the nf-core community. You are welcome to join any or all of these at any time!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestions about Nextflow that are not related to nf-core can be asked on the Nextflow Slack.\n\n\n\n\nThis tutorial will make use of the nf-core/tools, a set of helper tools for use with Nextflow workflows. These tools have been developed to provide a range of additional functionality using, developing and testing workflows.\nThe nf-core tool is written in Python and is available from the Python Package Index (PyPI).\npip install nf-core\nAlternatively, nf-core/tools can also be installed from Bioconda:\nconda install -c bioconda nf-core\n\n\n\n\n\n\nChallenge\n\n\n\nFind out what version of nf-core/tools you have available using the --version option:\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nUse the --version option to print your version of the nf-core/tools:\nnf-core --version\n\n\n\n\n\n\nTip\n\n\n\nnf-core/tools has commands to help both users and developers. The tooling is for everyone. For users, the helper tools make it easier to run workflows. For developers, the helper tools make it easier to develop your workflows using best practises.\n\n\n\n\nFind out what other nf-core/tools options and commands are available using the --help option:\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nRun the --help option to list the options, tools for users, and tools for developers\nnf-core --help\n\n\n\n\n\n\nThere are currently 80 workflows (March 2023) available as part of nf-core. These workflows are at various stages of development with 49 released, 19 under development, and 12 archived. A full list of workflows, as well as their documentation, can be explored on the nf-core website.\nThe nf-core list command can also be used to print the available nf-core workflows along with local information.\n:::\n\n\nTry to find out which workflows are available using nf-core/tools:\n:::\n\n\n\n\n\n\nSolution\n\n\n\n\n\nRun the list command to see what workflows are available.\nnf-core list\n\n\n\nThe output shows the latest workflow version number and when that was released. You will also be shown if and when a workflow was pulled locally and whether you have the latest version.\nUnless you are actively developing workflow code, you can use Nextflow‚Äôs built-in functionality to fetch nf-core workflows. You can use the Nextflow pull command to download a remote workflow from the nf-core GitHub repository:\nnextflow pull nf-core/&lt;PIPELINE&gt;\nNextflow can also fetch the workflow code when you run it without pulling the workflow beforehand:\nnextflow run nf-core/&lt;PIPELINE&gt;\n\nNextflow will fetch the default git branch if a workflow version is not specified. This will be the master branch for workflows with a stable release.\n\n\n\n\n\n\n\nReminder\n\n\n\nYou can explicitly reference the workflow version number that you wish to use with the -revision or -r flag.\n\n\nnf-core workflows use GitHub releases to tag stable versions of the code and software. You will always be able to run a previous version of a workflow once it is released.\n\n\n\n\n\n\nChallenge\n\n\n\nTry to pull the latest version of the nf-core/rnaseq workflow directly from GitHub using Nextflow and check what version you have locally.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nUse nextflow pull to download the rnaseq workflow from the nf-core GitHub repository.\nnextflow pull nf-core/rnaseq\nUse nf-core list to view what version of the workflow you have locally\nnf-core list\nAll materials copyright Sydney Informatics Hub, University of Sydney"
  },
  {
    "objectID": "notebooks/1.2_nfcore.html#key-features-of-nf-core-workflows",
    "href": "notebooks/1.2_nfcore.html#key-features-of-nf-core-workflows",
    "title": "Introduction to nf-core",
    "section": "",
    "text": "Documentation\nnf-core workflows have extensive documentation covering installation, usage, and description of output files to ensure that you won‚Äôt be left in the dark.\n\nCI Testing\n\nEvery time a change is made to the workflow code, nf-core workflows use continuous-integration testing to ensure that nothing has broken.\n\nStable Releases\n\nnf-core workflows use GitHub releases to tag stable versions of the code and software, making workflow runs totally reproducible.\n\nPackaged software\n\nPipeline dependencies are automatically downloaded and handled using Docker, Singularity, Conda, or other software management tools. There is no need for any software installations.\n\nPortable and reproducible\n\nnf-core workflows follow best practices to ensure maximum portability and reproducibility. The large community makes the workflows exceptionally well-tested and easy to run.\n\nCloud-ready\n\nnf-core workflows are tested on AWS after every major release. You can even browse results live on the website and use outputs for your own benchmarking.\n\n\nAll nf-core workflows are open-source and community driven."
  },
  {
    "objectID": "notebooks/1.2_nfcore.html#events",
    "href": "notebooks/1.2_nfcore.html#events",
    "title": "Introduction to nf-core",
    "section": "",
    "text": "nf-core events are community-driven gatherings that provide a platform to discuss the latest developments in Nextflow and nf-core workflows. These events typically include a combination of community seminars, trainings, and hackathons, and are open to anyone who is interested in using and developing nf-core and its applications. Most events are held virtually, making them accessible to a global audience.\nUpcoming events are listed on the nf-core event page and announced on Slack and Twitter."
  },
  {
    "objectID": "notebooks/1.2_nfcore.html#join-the-community",
    "href": "notebooks/1.2_nfcore.html#join-the-community",
    "title": "Introduction to nf-core",
    "section": "",
    "text": "There are several ways you can join the nf-core community. You are welcome to join any or all of these at any time!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestions about Nextflow that are not related to nf-core can be asked on the Nextflow Slack."
  },
  {
    "objectID": "notebooks/1.2_nfcore.html#nf-core-tooling",
    "href": "notebooks/1.2_nfcore.html#nf-core-tooling",
    "title": "Introduction to nf-core",
    "section": "",
    "text": "This tutorial will make use of the nf-core/tools, a set of helper tools for use with Nextflow workflows. These tools have been developed to provide a range of additional functionality using, developing and testing workflows.\nThe nf-core tool is written in Python and is available from the Python Package Index (PyPI).\npip install nf-core\nAlternatively, nf-core/tools can also be installed from Bioconda:\nconda install -c bioconda nf-core\n\n\n\n\n\n\nChallenge\n\n\n\nFind out what version of nf-core/tools you have available using the --version option:\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nUse the --version option to print your version of the nf-core/tools:\nnf-core --version\n\n\n\n\n\n\nTip\n\n\n\nnf-core/tools has commands to help both users and developers. The tooling is for everyone. For users, the helper tools make it easier to run workflows. For developers, the helper tools make it easier to develop your workflows using best practises.\n\n\n\n\nFind out what other nf-core/tools options and commands are available using the --help option:\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nRun the --help option to list the options, tools for users, and tools for developers\nnf-core --help"
  },
  {
    "objectID": "notebooks/1.2_nfcore.html#finding-a-nf-core-workflow",
    "href": "notebooks/1.2_nfcore.html#finding-a-nf-core-workflow",
    "title": "Introduction to nf-core",
    "section": "",
    "text": "There are currently 80 workflows (March 2023) available as part of nf-core. These workflows are at various stages of development with 49 released, 19 under development, and 12 archived. A full list of workflows, as well as their documentation, can be explored on the nf-core website.\nThe nf-core list command can also be used to print the available nf-core workflows along with local information.\n:::\n\n\nTry to find out which workflows are available using nf-core/tools:\n:::\n\n\n\n\n\n\nSolution\n\n\n\n\n\nRun the list command to see what workflows are available.\nnf-core list\n\n\n\nThe output shows the latest workflow version number and when that was released. You will also be shown if and when a workflow was pulled locally and whether you have the latest version.\nUnless you are actively developing workflow code, you can use Nextflow‚Äôs built-in functionality to fetch nf-core workflows. You can use the Nextflow pull command to download a remote workflow from the nf-core GitHub repository:\nnextflow pull nf-core/&lt;PIPELINE&gt;\nNextflow can also fetch the workflow code when you run it without pulling the workflow beforehand:\nnextflow run nf-core/&lt;PIPELINE&gt;\n\nNextflow will fetch the default git branch if a workflow version is not specified. This will be the master branch for workflows with a stable release.\n\n\n\n\n\n\n\nReminder\n\n\n\nYou can explicitly reference the workflow version number that you wish to use with the -revision or -r flag.\n\n\nnf-core workflows use GitHub releases to tag stable versions of the code and software. You will always be able to run a previous version of a workflow once it is released.\n\n\n\n\n\n\nChallenge\n\n\n\nTry to pull the latest version of the nf-core/rnaseq workflow directly from GitHub using Nextflow and check what version you have locally.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nUse nextflow pull to download the rnaseq workflow from the nf-core GitHub repository.\nnextflow pull nf-core/rnaseq\nUse nf-core list to view what version of the workflow you have locally\nnf-core list"
  }
]